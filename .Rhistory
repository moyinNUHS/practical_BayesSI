library(viridis)
library(stringr)
library(ggplot2)
################
# PREPARE DATA #
################
#import GPS data
location.df.acorn2 = read.csv('~/Documents/nBox/ADVANCE-ID/ACORN-HAI/protocol/manuscript/resources/ACORN2_site_GPS_data_Dec-2022.csv')
location.df.acorn2$study.type = 'ACORN II'
location.df.acorn2$country = sub("\\ - .*", "", location.df.acorn2$Site.name)
location.df.acorn2 = location.df.acorn2[,-which(colnames(location.df.acorn2) == 'Site')]
location.df.acornhai = read.csv('~/Documents/nBox/ADVANCE-ID/ACORN-HAI/protocol/manuscript/resources/ACORNHAI_site_GPS_data_Dec-2022.csv')
location.df.acornhai$study.type = 'ACORN-HAI'
colnames(location.df.acornhai)[4] = 'country'
location.df = rbind(location.df.acorn2, location.df.acornhai)
location.df$Site.name = trimws(location.df$Site.name)
#overlapping sites
location.df = location.df[-which(location.df$Site.name %in%
c('Vietnam - National Hospital for Tropical Diseases',
'Nepal - B.P. Koirala Institute of Health Sciences',
'Nepal - Patan Hospital')),]
location.df$study.type[location.df$Site.name %in% c('NHTD - Hanoi',
'B.P. Koirala Institute of Health Sciences',
'Patan Hospital')] = 'Both ACORN II and ACORN-HAI'
###################
# PREPARE MAP DATA#
###################
# country codes in gapminder::country_codes
gapminder_codes = gapminder::country_codes
# countries with info in gapminder::gapminder_unfiltered
gapminder = gapminder::gapminder_unfiltered
# join both datasets with inner_join to get a dataset with the info by country, continent and country-code
gapminder <- gapminder %>%
inner_join(gapminder_codes, by = "country") %>%
mutate(code = iso_alpha)
gapminder_data <- gapminder %>%
inner_join(maps::iso3166 %>%
select(a3, mapname), by = c(code = "a3")) %>%
mutate(mapname = str_remove(mapname, "\\(.*"))
d.country = map_data("world") %>%
tbl_df() %>%
inner_join(gapminder_data, by=c(region= "mapname")) %>%
filter(year == 2007)
d.country$participating = 0
d.country$participating[which(d.country$country %in% location.df$country)] = 1
# A base map of the world (Antarctica removed)
d.country <- d.country[which(d.country$continent %in% c('Asia', 'Africa')),]
#############
# PLOT MAP  #
#############
png("~/Documents/nBox/ADVANCE-ID/ACORN-HAI/protocol/manuscript/submission/graphics/site_map.png",
width = 1500, height = 750, pointsize = 6)
ggplot() +
geom_polygon(data = d.country, aes(long, lat, group = group, fill = as.factor(participating)), color = "white", size = 0.05) +
scale_fill_manual(values = c("grey80","#9dc2c4")) +
geom_point(aes(x = Longitude, y = Latitude, colour = as.factor(study.type)), pch = 18, alpha = 0.8, size = 4,  data = location.df) +
scale_colour_manual(values = c("#F76C5E", "#E3C16F", "#3066BE"), name = '') +
theme(
axis.line = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
plot.background = element_rect(fill = "white", color = NA),
panel.background = element_rect(fill = "white", color = NA),
legend.text = element_text(color = "grey40", size = 16, hjust = 0),
legend.position = c(0.85, 0.25),
legend.background = element_blank(),
legend.key.size = unit(1, "cm"),
legend.key = element_rect(fill = "white"),
plot.margin = unit(c(-1,-20,-3,-30), "cm")) +
guides(fill = "none",
color = guide_legend(override.aes = list(size=5))) +
coord_fixed (ratio = 1.2)
dev.off()
disease.severity = rnorm(10)
disease.severity
disease.severity = abs(rnorm(10))
disease.severity
outcome = rbinom(10, prob = disease.severity)
dz.severity = rnorm(10)
dz.severity = abs(rnorm(10))
dz.severity
outcome = rbinom(10)
outcome = rbinom(10, 10)
outcome = rbinom(10, 10, dz.severity)
outcome
outcome = rbinom(1, 10, dz.severity)
outcome
outcome = rbinom(10, 1, dz.severity)
outcome
data.frame(id, dz.severity, outcome)
id = 1:10
dz.severity = abs(rnorm(10))
outcome = rbinom(10, 1, dz.severity)
data.frame(id, dz.severity, outcome)
library(gsDesign)
setwd("/Users/moyin/Documents/GitHub")
install.packages("devtools")
devtools::install_github("mjg211/multiarm")
?des_dtl_bern
library(multiarm)
?des_dtl_bern
??des_dtl_bern
des_dtl_bern()
des_dtl_bern
components_dtl_init
??components_dtl_init
?components_dtl_init
install.packages('DunnettTests')
install.packages('multcomp”')
install.packages('multcomp')
library(multcomp)
d = data.frame(id = 1:100,
tx = sample(c('A, B, C, D'), c(0.25, 0.25, 0.25, 0.25))
)
d = data.frame(id = 1:100,
tx = sample(c('A, B, C, D'), c(0.25, 0.25, 0.25, 0.25), 100)
)
?sample
d = data.frame(id = 1:100,
tx = sample(c('A, B, C, D'), 100, c(0.25, 0.25, 0.25, 0.25))
)
d = data.frame(id = 1:100,
tx = sample(c('A, B, C, D'), 100, T)
)
d
d = data.frame(id = 1:100,
tx = sample(c('A', 'B', 'C', 'D'), 100, T)
)
d
d = data.frame(id = 1:400,
tx = rep(c('A', 'B', 'C', 'D'), each = 100)
outcome = c(rep(c('0', '1'), each = 50),
c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50))
d = data.frame(id = 1:400,
tx = rep(c('A', 'B', 'C', 'D'), each = 100),
outcome = c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50))
)
d = data.frame(id = 1:400,
tx = rep(c('A', 'B', 'C', 'D'), each = 100),
outcome = c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50))
)
head(d)
d = data.frame(id = 1:400,
treatment = rep(c('A', 'B', 'C', 'D'), each = 100),
outcome = c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50))
)
model <- lm(y ~ treatment, data = d)
d = data.frame(id = 1:400,
treatment = rep(c('A', 'B', 'C', 'D'), each = 100),
outcome = c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50))
)
head(d)
model <- lm(outcome ~ treatment, data = d)
model
d = apply(d, 2, as.factor)
d
d = lapply(d, 2, as.factor)
d = data.frame(id = 1:400,
treatment = as.factor(rep(c('A', 'B', 'C', 'D'), each = 100)),
outcome = as.factor(c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50)))
)
head(d)
model <- lm(outcome ~ treatment, data = d)
model <- glm(outcome ~ treatment, data = d)
d = data.frame(id = 1:400,
treatment = as.factor(rep(c('A', 'B', 'C', 'D'), each = 100)),
outcome = as.factor(c(rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50),
rep(c('0', '1'), each = 50)))
)
head(d)
summary(d)
d$treatment
d$outcome
rep(c('0', '1'), c(40, 60)))
d = data.frame(id = 1:400,
treatment = as.factor(rep(c('A', 'B', 'C', 'D'), each = 100)),
outcome = as.factor(c(rep(c('0', '1'), c(50, 50)),
rep(c('0', '1'), c(10, 90)),
rep(c('0', '1'), c(30, 70)),
rep(c('0', '1'), c(40, 60))))
)
head(d)
model <- glm(outcome ~ treatment, data = d)
d = data.frame(id = 1:400,
treatment = as.factor(rep(c('A', 'B', 'C', 'D'), each = 100)),
outcome = as.factor(c(rep(c('0', '1'), c(50, 50)),
rep(c('0', '1'), c(10, 90)),
rep(c('0', '1'), c(30, 70)),
rep(c('0', '1'), c(40, 60))))
)
head(d)
glm(outcome ~ treatment, data = d)
head(d)
tail(d)
d[which(d$treatment == 'C')]
d[which(d$treatment == 'C'),]
model = glm(outcome ~ treatment, data = d)
d = data.frame(id = 1:400,
treatment = as.factor(rep(c('A', 'B', 'C', 'D'), each = 100)),
outcome = as.numeric(c(rep(c('0', '1'), c(50, 50)),
rep(c('0', '1'), c(10, 90)),
rep(c('0', '1'), c(30, 70)),
rep(c('0', '1'), c(40, 60))))
)
head(d)
model = glm(outcome ~ treatment, data = d)
model
dunnett_test = multcomp::glht(model, linfct = mcp(treatment = "A"))
dunnett_test
dunnett_test = multcomp::glht(model, linfct = mcp(treatment = "A"))
step_down_test <- summary(test(dunnett_test, "StepDown"))
library(multcomp)
d = data.frame(id = 1:400,
treatment = as.factor(rep(c('A', 'B', 'C', 'D'), each = 100)),
outcome = as.numeric(c(rep(c('0', '1'), c(50, 50)),
rep(c('0', '1'), c(10, 90)),
rep(c('0', '1'), c(30, 70)),
rep(c('0', '1'), c(40, 60))))
)
head(d)
model = glm(outcome ~ treatment, data = d)
dunnett_test = glht(model, linfct = mcp(treatment = "A"))
step_down_test = summary(test(dunnett_test, "StepDown"))
?test
test(dunnett_test, "StepDown")
dunnett_test
step_down_test = summary(multcomp::test(dunnett_test, "StepDown"))
step_down_test = summary(dunnett_test, test = adjusted(type = "free"))
print(step_down_test)
? mcp
dunnett_test = glht(model,
linfct = mcp(treatment = "A"),
alternative = c("two.sided"))
step_down_test = summary(dunnett_test, test = adjusted(type = "free"))
dunnett_test
dunnett_test = glht(model,
linfct = mcp(treatment = A),
alternative = c("two.sided"))
summary(dunnett_test)
summary(model)
dunnett_test = glht(model,
linfct = mcp(treatment = "A"),
alternative = c("two.sided"))
summary(dunnett_test)
recovery.aov <- aov(minutes ~ blanket, data = recovery)
summary( recovery.aov)
summary(dunnett_test)
summary(model)
dunnett_test = glht(model,
linfct = mcp(treatment = "A"),
alternative = c("two.sided"))
summary(dunnett_test)
summary(dunnett_test, test = adjusted(type = "free"))
head(recovery)
summary(recovery)
dunnett_test = glht(model,
linfct = mcp(treatment = "Dunnett"),
alternative = c("two.sided"))
summary(dunnett_test)
summary(dunnett_test, test = adjusted(type = "free"))
summary(model)
summary(model)$coeff
summary(model)$coeff[,3]
summary(model)$coeff[,4]
round(summary(model)$coeff[,4], 3)
round(summary(model)$coeff[,4], 5)
round(summary(model)$coeff[2:4,4], 5)
summary(dunnett_test)
stepdown = summary(dunnett_test, test = adjusted(type = "free"))
stepdown
data.frame(round(summary(model)$coeff[2:4,4], 5),
round(summary(dunnett_test)$coeff[2:4,4], 5),
round(stepdown$coeff[2:4,4], 5)
)
data.frame(round(summary(model)$coeff[2:4,4], 5),
round(summary(dunnett_test)$coeff[2:4,4], 5),
round(summary(stepdown)$coeff[2:4,4], 5)
)
data.frame(round(summary(model)$coeff[2:4,4], 5),
round(summary(dunnett_test)$coeff[,4], 5),
round(summary(stepdown)$coeff[,4], 5)
)
round(summary(model)$coeff[2:4,4], 5)
round(summary(dunnett_test)$coeff[,4], 5)
summary(dunnett_test)
str(summary(dunnett_test))
summary(dunnett_test)$pvalues
summary(dunnett_test)$test
summary(dunnett_test)$test$pvalues
summary(dunnett_test)
summary(dunnett_test)$test
summary(dunnett_test)$test$pvalues
str(summary(dunnett_test)$test$pvalues)
summary(stepdown)
data.frame(round(summary(model)$coeff[2:4,4], 5),
round(summary(dunnett_test)$test$pvalues, 5),
round(summary(stepdown)$test$pvalues, 5)
)
data.frame(unadj = round(summary(model)$coeff[2:4,4], 5),
dunnett = round(summary(dunnett_test)$test$pvalues, 5),
stepdowndunnett = round(summary(stepdown)$test$pvalues, 5)
)
# Output
data.frame(unadj = round(summary(model)$coeff[2:4,4], 5),
dunnett = round(summary(dunnett_test)$test$pvalues, 5),
stepdowndunnett = round(summary(stepdown)$test$pvalues, 5),
bonferroni = round(summary(model)$coeff[2:4,4], 5)/3)
0.05/3
0.025/3
1-0.025/3 = 0.00833
1-0.025/3
c = ' Hsu Li Yang1,3, Cao Yang6, H. Rogier van Doorn2,7,  Louise Thwaites2,8, Yen Lam Minh8, Abhilasha Karkey2,9,  Jeanette Teo10, Andrea Kwa Lay Hoon11,  Indumathi Venkatachalam12, Kalisvar Marimuthu13,14,  Ng Oon Tek13, 14, Shawn Vasoo13,14, Suwatthiya Kitsaran15, Siriluck Anunnatsiri16, Pope Kosalaraksa17,  Darunee Chotiprasitsakul18, Pitak Santanirand18, Rongpong Plongla19, Chua Hock Hin20, Xun Ting Tiong20, Wong Ke Juin21,  Sasheela A/P Sri La Sri Ponnampalavanar22, Helmi Bin Sulaiman22,  Mohd Zulfakar Mazlan23, Zeti Norfidiyati Salmuna24, Giri Shan Rajahram25, Mohd Zaki Bin Mohd Zaili26, Joshua R. Francis27,  Nevio Sarmento27,28,  Helio Guterres29,  Tessa Oakley27,  Jennifer Yan27, Ari Tilman28,  Muhammad Osama Rehman Khalid30, Madiha Hashmi30, Faisal Mahmood31, Inke Nadia D. Lubis32, Hendri Wijaya32,33, Cybele L. Abad34, Arthur Dessi Roman35, Cecilia C. Maramba- Lazarte35,  Gazi Md. Salahuddin Mamun36,  Dayang Hjh Rosmonaliza Binti Hj Awang Asli37, Muhd Haziq Fikry bin Haji Abdul Momin37, Ulziijargal Gurjav38, Azizullah Khan  Dhiloo39, Ambreen Fatima39, Bory Sotharith40, George M. Varghese41, Lalit Gupta42, Pratik Tantia43'
length(grep(',', c))
sim_data = gen.data(
no_pattern,
size_pattern,
pattern,
res_probability_prior,
res_probability_all,
differsite
)
# clean environment
rm(list = ls())
# set working directory to the `practical/` folder
wd = '~/Documents/GitHub/practical/'
setwd(wd)
# load libraries and functions
scripts = paste0(wd, 'Code/Functions/', list.files('Code/Functions/'))
lapply(scripts, source)
# set seed for reproducibility
set.seed(3127)
prob_pattern = c(P1 = 0.25, P2 = 0.25, P3 = 0.25, P4 = 0.25) # Prevalence of each pattern
T_vector = c(0.9, 0.6, 0.3, 0.1)  # Treatment effects - first one being reference
res_rate_prior = c(0.9, 0.6, 0.3, 0.1) # Priors
N = 300 # Max number of patients
N_iter = 1          # Number of iterations
no_treatment = 4
# No. of treatments within simulation
pattern_list = list( # Treatment patterns
pattern1 = c(2, 3),
pattern2 = c(1, 2, 3),
pattern3 = c(2, 3, 4),
pattern4 = c(1, 2, 3, 4))
differsite=0
#Specify each treatment risk
alpha_ref = find_phi(p = T_vector[1], alpha = 0)   # reference treatment effect
phi_vector = find_phi(p = T_vector, alpha = alpha_ref) # specify each treatment effect in terms of OR
#Specify sample size for each run
res_rate_mat = matrix(
T_vector,
byrow = T,
nrow = length(pattern_list),
# number of patterns
ncol = length(T_vector)
)     # number of treatments
res_rate_mat_prior = matrix(
res_rate_prior,
byrow = T,
nrow = length(pattern_list),
ncol = length(res_rate_prior)
)
phi_v = phi_vector
pattern = pattern_list
res_probability_prior = res_rate_mat_prior
res_probability_all = res_rate_mat
prob_pattern = prob_pattern
R = N_iter
alt_hypothesis = 'two.sided'
type1correction = T
sim_data = gen.data(
no_pattern,
size_pattern,
pattern,
res_probability_prior,
res_probability_all,
differsite
)
sim_data = gen.data(
no_pattern = 4,
size_pattern,
pattern,
res_probability_prior,
res_probability_all,
differsite
)
# Becky -
# Yes I agree with your description of the way the model is implemented in R.
# But the two models are equivalent, aren’t they?,
# and the one implemented in R is a reparameterization of the model described in the paper,
# so the results would be identical.
# I think the way it’s described in the paper feels like a more natural way to explain the model in words.
size_pattern <<- apply(assigned_pattern, 2, sum)
# Becky -
# Yes I agree with your description of the way the model is implemented in R.
# But the two models are equivalent, aren’t they?,
# and the one implemented in R is a reparameterization of the model described in the paper,
# so the results would be identical.
# I think the way it’s described in the paper feels like a more natural way to explain the model in words.
no_pattern <<- length(pattern)
no_treatment <<- length(unique(unlist(pattern)))
#res_probability_all<-matrix(rep(response_prob_V, no_pattern), ncol = no_treatment, byrow = T)
colnames(res_probability_all) <-
sapply(1:no_treatment, function(i) {
paste0("treatment_", i)
})
rownames(res_probability_all) <-
sapply(1:no_pattern, function(i) {
paste0("alpha_", i)
})
# generate which pattern each patient in N patients belong to
# each person has prob_pattern to be allocated to one of the treatment patterns
assigned_pattern <- t(rmultinom(N, size = 1, prob_pattern))
colnames(assigned_pattern) <-
sapply(1:no_pattern, function(i) {
paste0("subgroup", i)
})
# number of patients in each subgroup that is defined by the pattern
size_pattern <<- apply(assigned_pattern, 2, sum)
lambda <- prob_pattern # true prevalence rate of patterns
true.response.r <-
lapply(1:no_pattern, function(i)
res_probability_all[i, pattern[[i]]])
true.mean.min <- lapply(1:no_pattern, function(i) {
v <- true.response.r[[i]]
c("mean" = mean(v), "min" = min(v))
})
# computes the mean and minimum values of the treatment effects in each pattern
true.mean.min <- do.call(cbind, true.mean.min)
sim_data = gen.data(
no_pattern = 4,
size_pattern ,
pattern,
res_probability_prior,
res_probability_all,
differsite
)
sim_data
prob_pattern = c(P1 = 0.25, P2 = 0.25, P3 = 0.25, P4 = 0.25) # Prevalence of each pattern
T_vector = c(0.9, 0.6, 0.3, 0.1)  # Treatment effects - first one being reference
no_pattern <- length(pattern)
no_treatment <- length(unique(unlist(pattern)))
#res_probability_all<-matrix(rep(response_prob_V, no_pattern), ncol = no_treatment, byrow = T)
# response rate: row = pattern, column = treatment
colnames(res_probability_all) <-
sapply(1:no_treatment, function(i) {
paste0("treatment_", i)
})
rownames(res_probability_all) <-
sapply(1:no_pattern, function(i) {
paste0("alpha_", i)
})
# generate which pattern each patient in N patients belong to
# each person has prob_pattern to be allocated to one of the treatment patterns
assigned_pattern <- t(rmultinom(N, size = 1, prob_pattern))
colnames(assigned_pattern) <-
sapply(1:no_pattern, function(i) {
paste0("subgroup", i)
})
# number of patients in each subgroup that is defined by the pattern
size_pattern <- apply(assigned_pattern, 2, sum)
lambda <- prob_pattern # true prevalence rate of patterns
sim_data = gen.data(
no_pattern,
size_pattern,
pattern,
res_probability_prior,
res_probability_all,
differsite
)
length(sim_data)
d = sim_data$trial_data
alldata = sim_data$trial_data
nma_data <- data.frame(y = unlist(alldata[1,]),
treatment = factor(unlist(alldata[2,]), levels = sort(unique(unlist(alldata[2,])))),
subgroup = factor(unlist(alldata[4,]))#,
#site=factor(unlist(alldata[5,]))
)
my.glm <- glm(y ~ treatment + subgroup, family = "binomial", data = d)
nma_data
my.glm <- glm(y ~ treatment + subgroup, family = "binomial", data = nma_data)
my.glm
becky <- glm(y ~ treatment + subgroup, family = "binomial", data = nma_data)
my.glm <- glm(y ~ treatment | subgroup, family = "binomial", data = nma_data)
my.glm <- glm(y ~ treatment + (1 | subgroup), family = "binomial", data = nma_data)
becky <- glm(y ~ treatment + subgroup, family = "binomial", data = nma_data)
my.glm <- glm(y ~ treatment + (1 | subgroup), family = "binomial", data = nma_data)
my.glm <- glmer(y ~ treatment + (1 | subgroup), family = "binomial", data = nma_data)
my.glm
becky
